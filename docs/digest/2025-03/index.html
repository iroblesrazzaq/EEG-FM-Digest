<!doctype html>
<html><head><meta charset='utf-8'><title>EEG-FM Digest 2025-03</title>
<link rel='stylesheet' href='../../assets/style.css'></head>
<body>
  <main>
    <h1>EEG Foundation Model Digest — 2025-03</h1>
    <section class='digest-about'><h2>About This Digest</h2><p>[why i made digest, how it works]</p></section>
    <p>Top picks: 2503.10362, 2503.02636</p>
    <section><h2>new_model</h2>
    <article class='paper-card' id='2503.02636'>
      <h3><a href='http://arxiv.org/abs/2503.02636v4'>YARE-GAN: Yet Another Resting State EEG-GAN</a></h3>
      <div class='meta'>2025-03-04 · Yeganeh Farahzadi, Morteza Ansarinia, Zoltan Kekecs</div>
      <p><strong>Summary Highlights:</strong></p>
      <ul class='summary-points'><li>New EEG foundation model: YARE-GAN generates realistic resting-state EEG signals and extracts unsupervised representations via a Wasserstein GAN with gradient penalty.</li><li>Method novelty: Incorporates self-attention, positional encoding, and subject-specific transformation layers to capture temporal dependencies and individual variability in EEG data.</li><li>Strong evidence: Generated signals match real EEG in spectral properties and connectivity; discriminator representations achieve 73% gender classification accuracy, outperforming raw EEG and matching CBraMod with 1/10th the data and compute.</li></ul>
      <p><strong>Unique contribution:</strong> Demonstrates that GAN-based architectures can serve dual roles in EEG research: high-fidelity signal synthesis and powerful unsupervised feature extraction, with downstream task performance matching data-intensive foundation models.</p>
      <details class='summary-detail'><summary>Detailed summary</summary><p>This paper introduces YARE-GAN, a Wasserstein GAN with gradient penalty designed to generate realistic multi-channel resting-state EEG signals and extract unsupervised representations. The model incorporates self-attention layers, positional encoding, and a subject-specific transformation layer to capture temporal dependencies and individual variability. Trained on the MPI-LEMON dataset (54.13 hours, 216 participants, 8 selected channels), it generates EEG signals that closely match real data in time/frequency domains and inter-channel connectivity. Critically, the discriminator&#x27;s intermediate representations are repurposed for a downstream gender classification task, achieving 73% accuracy—outperforming raw EEG and matching CBraMod foundation model performance while using far less data and computational resources.</p></details>
      <p class='chips'><span class='chip chip-paper_type' title='paper type'>New Model</span> <span class='chip chip-backbone' title='backbone'>Transformer</span> <span class='chip chip-objective' title='objective'>Contrastive</span> <span class='chip chip-tokenization' title='tokenization'>Time Patch</span> <span class='chip chip-topology' title='topology'>Fixed Montage</span></p>
      <p><a href='https://github.com/Yeganehfrh/YARE-GAN'>code</a> </p>
    </article>
    

    <article class='paper-card' id='2503.10362'>
      <h3><a href='http://arxiv.org/abs/2503.10362v1'>BioSerenity-E1: a self-supervised EEG model for medical applications</a></h3>
      <div class='meta'>2025-03-13 · Ruggero G. Bettinardi, Mohamed Rahmouni, Ulysse Gimenez</div>
      <p><strong>Summary Highlights:</strong></p>
      <ul class='summary-points'><li>New EEG foundation model: BioSerenity-E1 uses a two-phase self-supervised pretraining framework combining spectral tokenization with masked prediction.</li><li>Novel architecture: The model employs a transformer-based VQ-VAE to learn compressed representations of log-multitaper spectral projections, followed by extensive masked token prediction.</li><li>Strong clinical performance: Achieves state-of-the-art results across seizure detection, normal/abnormal classification, and multiclass pathology tasks, with particular advantages in low-data scenarios.</li></ul>
      <p><strong>Unique contribution:</strong> BioSerenity-E1 is the first self-supervised foundation model for clinical EEG that combines spectral tokenization with masked prediction, achieving state-of-the-art performance while requiring minimal labeled data.</p>
      <details class='summary-detail'><summary>Detailed summary</summary><p>BioSerenity-E1 introduces a two-phase self-supervised pretraining framework for clinical EEG applications. The model first learns compressed EEG representations via a transformer-based VQ-VAE architecture that reconstructs log-multitaper spectral projections, then implements extensive (70% block) masked token prediction to learn complex spatiotemporal dependencies. Pre-trained on 4,000 hours of clinical EEG data, BioSerenity-E1 achieves strong performance across three clinical tasks: seizure detection (AUROC = 0.926, Sensitivity = 0.909), normal/abnormal classification (AUPRC = 0.970 on proprietary data; 0.910 on TUH-Abnormal), and multiclass pathology differentiation (Weighted F1 = 0.730). The model demonstrates particular utility in low-data regimes, showing improvements of 2-17% in AUPRC when trained on less than 10% of available data.</p></details>
      <p class='chips'><span class='chip chip-paper_type' title='paper type'>New Model</span> <span class='chip chip-backbone' title='backbone'>Transformer</span> <span class='chip chip-objective' title='objective'>Masked Reconstruction</span> <span class='chip chip-objective' title='objective'>Discrete Code Prediction</span> <span class='chip chip-tokenization' title='tokenization'>Discrete Tokens</span> <span class='chip chip-topology' title='topology'>Fixed Montage</span></p>
      <p> </p>
    </article>
    </section>
  </main>
  <script src='../../assets/site.js'></script>
</body></html>
