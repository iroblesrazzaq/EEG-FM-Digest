<!doctype html>
<html><head><meta charset='utf-8'><title>EEG-FM Digest 2021-01</title>
<link rel='stylesheet' href='../../assets/style.css'></head>
<body>
  <main>
    <h1>EEG Foundation Model Digest — 2021-01</h1>
    <section class='digest-about'><h2>About This Digest</h2><p>[why i made digest, how it works]</p></section>
    <p>Top picks: 2101.12037</p>
    <section><h2>new_model</h2>
    <article class='paper-card' id='2101.12037'>
      <h3><a href='http://arxiv.org/abs/2101.12037v1'>BENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data</a></h3>
      <div class='meta'>2021-01-28 · Demetres Kostas, Stephane Aroca-Ouellette, Frank Rudzicz</div>
      <p><strong>Summary Highlights:</strong></p>
      <ul class='summary-points'><li>New EEG foundation model: BENDR uses transformers and contrastive self-supervised learning to learn from massive unlabeled EEG datasets, adapting techniques from wav2vec 2.0.</li><li>Generalizes across domains: A single pretrained BENDR model works across different hardware, subjects, and tasks, showing strong performance on sleep staging, motor imagery, and P300 classification.</li><li>Outperforms prior work: BENDR achieves better results than previous self-supervised approaches for sleep stage classification while maintaining competitive performance on BCI tasks.</li></ul>
      <p><strong>Unique contribution:</strong> The paper introduces BENDR, a transformer-based EEG foundation model that adapts contrastive self-supervised learning from speech recognition to EEG, demonstrating generalizability across subjects, hardware, and tasks while outperforming prior self-supervised approaches.</p>
      <details class='summary-detail'><summary>Detailed summary</summary><p>This paper introduces BENDR, a transformer-based model for electroencephalography (EEG) that adapts techniques from language modeling and speech recognition to the EEG domain. The authors propose using contrastive self-supervised learning to pretrain on massive amounts of unlabeled EEG data, specifically adapting the wav2vec 2.0 framework. BENDR learns compressed representations (called BENDR vectors) from raw EEG signals through a two-stage architecture: a convolutional encoder that downsamples the signal, followed by a transformer encoder. The model is pretrained on the Temple University Hospital EEG Corpus and then fine-tuned on various downstream BCI and EEG classification tasks. The key innovation is demonstrating that a single pretrained model can generalize across different hardware, subjects, and tasks, outperforming prior work in sleep stage classification and showing competitive results on motor imagery and P300 speller tasks.</p></details>
      <p class='chips'><span class='chip chip-paper_type' title='paper type'>New Model</span> <span class='chip chip-backbone' title='backbone'>Transformer</span> <span class='chip chip-objective' title='objective'>Contrastive</span> <span class='chip chip-tokenization' title='tokenization'>Time Patch</span> <span class='chip chip-topology' title='topology'>Channel Flexible</span></p>
      <p><a href='https://github.com/SPOClab-ca/BENDR'>code</a> <a href='https://github.com/SPOClab-ca/BENDR'>weights</a></p>
    </article>
    </section>
  </main>
  <script src='../../assets/site.js'></script>
</body></html>
