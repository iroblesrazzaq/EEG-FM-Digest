{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# arXiv Sanity (Updated)\n",
    "\n",
    "This notebook supports two quick checks:\n",
    "- arXiv query-only count sanity (no LLM calls)\n",
    "- backend contracts for triage + summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f330ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/ismaelrobles-razzaq/2_cs_projects/eeg-fm-paper-roundup')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for candidate in [start, *start.parents]:\n",
    "        if (candidate / 'pyproject.toml').exists() and (candidate / 'src').exists():\n",
    "            return candidate\n",
    "    raise RuntimeError('Could not find repo root. Open notebook from this repo or set CWD accordingly.')\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "SRC_DIR = REPO_ROOT / 'src'\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from eegfm_digest.arxiv import fetch_query, in_month, category_match, dedupe_latest\n",
    "from eegfm_digest.keywords import QUERY_A, QUERY_B\n",
    "from eegfm_digest.triage import triage_paper, load_schema\n",
    "from eegfm_digest.summarize import summarize_paper\n",
    "from eegfm_digest.pdf import extract_text, slice_paper_text\n",
    "from eegfm_digest.llm_gemini import GeminiClient, LLMConfig, load_api_key\n",
    "\n",
    "REPO_ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "906cb8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRIAGE_PROMPT = (REPO_ROOT / 'prompts' / 'triage.md').read_text(encoding='utf-8')\n",
    "SUMMARIZE_PROMPT = (REPO_ROOT / 'prompts' / 'summarize.md').read_text(encoding='utf-8')\n",
    "REPAIR_PROMPT = (REPO_ROOT / 'prompts' / 'repair_json.md').read_text(encoding='utf-8')\n",
    "TRIAGE_SCHEMA = load_schema(REPO_ROOT / 'schemas' / 'triage.json')\n",
    "SUMMARY_SCHEMA = load_schema(REPO_ROOT / 'schemas' / 'summary.json')\n",
    "TRIAGE_MODEL = os.environ.get('GEMINI_MODEL_TRIAGE', 'gemini-3-flash-preview')\n",
    "SUMMARY_MODEL = os.environ.get('GEMINI_MODEL_SUMMARY', 'gemini-3-flash-preview')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## arXiv query-only sanity check\n",
    "\n",
    "Run a single arXiv `search_query` prompt and inspect how many results it returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the exact arXiv search_query prompt you want to test.\n",
    "ARXIV_QUERY = QUERY_A\n",
    "MONTH = None  # Set to None to skip month filtering.\n",
    "MAX_RESULTS = 10000\n",
    "RATE_LIMIT_SECONDS = 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query=all:(eeg OR electroencephalograph* OR brainwave*) AND all:(\"foundation model\" OR pretrain OR pretrained OR \"self-supervised\" OR \"self supervised\")\n",
      "raw_count=253\n",
      "category_match_count=233\n",
      "deduped_count=233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'arxiv_id_base': '1806.09532',\n",
       "  'published': '2018-06-20T11:34:36Z',\n",
       "  'title': 'Cross-paradigm pretraining of convolutional networks improves intracranial EEG decoding'},\n",
       " {'arxiv_id_base': '1811.07516',\n",
       "  'published': '2018-11-19T06:07:33Z',\n",
       "  'title': 'Unsupervised Learning in Reservoir Computing for EEG-based Emotion Recognition'},\n",
       " {'arxiv_id_base': '1911.05419',\n",
       "  'published': '2019-11-13T12:17:31Z',\n",
       "  'title': 'Self-supervised representation learning from electroencephalography signals'},\n",
       " {'arxiv_id_base': '2005.09687',\n",
       "  'published': '2020-05-19T18:10:35Z',\n",
       "  'title': 'Deep learning approaches for neural decoding: from CNNs to LSTMs and spikes to fMRI'},\n",
       " {'arxiv_id_base': '2007.04871',\n",
       "  'published': '2020-06-30T20:32:37Z',\n",
       "  'title': 'Subject-Aware Contrastive Learning for Biosignals'},\n",
       " {'arxiv_id_base': '2007.13018',\n",
       "  'published': '2020-07-25T21:59:17Z',\n",
       "  'title': 'Federated Self-Supervised Learning of Multi-Sensor Representations for Embedded Intelligence'},\n",
       " {'arxiv_id_base': '2007.16104',\n",
       "  'published': '2020-07-31T14:34:47Z',\n",
       "  'title': 'Uncovering the structure of clinical EEG signals with self-supervised learning'},\n",
       " {'arxiv_id_base': '2101.12037',\n",
       "  'published': '2021-01-28T14:54:01Z',\n",
       "  'title': 'BENDR: using transformers and a contrastive self-supervised learning task to learn from massive amounts of EEG data'},\n",
       " {'arxiv_id_base': '2104.08336',\n",
       "  'published': '2021-04-16T20:32:10Z',\n",
       "  'title': 'Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis'},\n",
       " {'arxiv_id_base': '2109.03124',\n",
       "  'published': '2021-09-07T14:42:55Z',\n",
       "  'title': 'GANSER: A Self-supervised Data Augmentation Framework for EEG-based Emotion Recognition'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = fetch_query(\n",
    "    query=ARXIV_QUERY,\n",
    "    max_results=MAX_RESULTS,\n",
    "    rate_limit_seconds=RATE_LIMIT_SECONDS,\n",
    ")\n",
    "\n",
    "raw_count = len(rows)\n",
    "if MONTH:\n",
    "    month_rows = [r for r in rows if in_month(r['published'], MONTH)]\n",
    "else:\n",
    "    month_rows = rows\n",
    "category_rows = [r for r in month_rows if category_match(r['categories'])]\n",
    "deduped_rows = dedupe_latest(category_rows)\n",
    "\n",
    "print(f'query={ARXIV_QUERY}')\n",
    "print(f'raw_count={raw_count}')\n",
    "if MONTH:\n",
    "    print(f'in_month_count={len(month_rows)}')\n",
    "print(f'category_match_count={len(category_rows)}')\n",
    "print(f'deduped_count={len(deduped_rows)}')\n",
    "\n",
    "[\n",
    "    {'arxiv_id_base': r['arxiv_id_base'], 'published': r['published'], 'title': r['title']}\n",
    "    for r in deduped_rows[:10]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113eff19",
   "metadata": {},
   "source": [
    "### Query A vs Query B counts\n",
    "\n",
    "Runs both canonical prompts and shows per-query counts plus a combined deduped union count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec663f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY_A counts: {'raw_count': 253, 'in_month_count': 253, 'category_match_count': 233, 'deduped_count': 233}\n",
      "QUERY_B counts: {'raw_count': 548, 'in_month_count': 548, 'category_match_count': 470, 'deduped_count': 470}\n",
      "combined_deduped_count: 594\n"
     ]
    }
   ],
   "source": [
    "def count_view(rows, month):\n",
    "    month_rows = [r for r in rows if in_month(r['published'], month)] if month else rows\n",
    "    category_rows = [r for r in month_rows if category_match(r['categories'])]\n",
    "    deduped_rows = dedupe_latest(category_rows)\n",
    "    return {\n",
    "        'raw_count': len(rows),\n",
    "        'in_month_count': len(month_rows),\n",
    "        'category_match_count': len(category_rows),\n",
    "        'deduped_count': len(deduped_rows),\n",
    "    }, deduped_rows\n",
    "\n",
    "rows_a = fetch_query(query=QUERY_A, max_results=MAX_RESULTS, rate_limit_seconds=RATE_LIMIT_SECONDS)\n",
    "rows_b = fetch_query(query=QUERY_B, max_results=MAX_RESULTS, rate_limit_seconds=RATE_LIMIT_SECONDS)\n",
    "\n",
    "counts_a, deduped_a = count_view(rows_a, MONTH)\n",
    "counts_b, deduped_b = count_view(rows_b, MONTH)\n",
    "combined_deduped = dedupe_latest(deduped_a + deduped_b)\n",
    "\n",
    "print('QUERY_A counts:', counts_a)\n",
    "print('QUERY_B counts:', counts_b)\n",
    "print('combined_deduped_count:', len(combined_deduped))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper = {\n",
    "    'arxiv_id': '2501.00001v1',\n",
    "    'arxiv_id_base': '2501.00001',\n",
    "    'version': 1,\n",
    "    'title': 'Example EEG Foundation Model Paper',\n",
    "    'summary': 'We propose a self-supervised EEG pretraining framework for transfer across tasks.',\n",
    "    'authors': ['Author A', 'Author B'],\n",
    "    'categories': ['cs.LG', 'q-bio.NC'],\n",
    "    'published': '2025-01-10T00:00:00Z',\n",
    "    'updated': '2025-01-10T00:00:00Z',\n",
    "    'links': {'abs': 'https://arxiv.org/abs/2501.00001', 'pdf': None},\n",
    "}\n",
    "paper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc81eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "triage_client = GeminiClient(\n",
    "    LLMConfig(\n",
    "        api_key=load_api_key(),\n",
    "        model=TRIAGE_MODEL,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=1024,\n",
    "    )\n",
    ")\n",
    "triage = triage_paper(\n",
    "    paper=paper,\n",
    "    llm=triage_client,\n",
    "    prompt_template=TRIAGE_PROMPT,\n",
    "    repair_template=REPAIR_PROMPT,\n",
    "    schema=TRIAGE_SCHEMA,\n",
    ")\n",
    "triage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a31a8fe",
   "metadata": {},
   "source": [
    "## Summary payload mode check\n",
    "\n",
    "If `fulltext` prompt tokens are too large, summarization automatically falls back to `fulltext_slices`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d277290",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = REPO_ROOT / 'data' / 'EEGFormer_eegfm.pdf'\n",
    "out_dir = REPO_ROOT / 'outputs' / '_sanity'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "text_path = out_dir / 'eegformer.txt'\n",
    "assert pdf_path.exists(), f'Missing PDF at {pdf_path}'\n",
    "meta = extract_text(pdf_path, text_path)\n",
    "raw_text = text_path.read_text(encoding='utf-8')\n",
    "slices = slice_paper_text(raw_text)\n",
    "meta, {k: len(v) for k, v in slices.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d893d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_client = GeminiClient(\n",
    "    LLMConfig(\n",
    "        api_key=load_api_key(),\n",
    "        model=SUMMARY_MODEL,\n",
    "        temperature=0.2,\n",
    "        max_output_tokens=2048,\n",
    "    )\n",
    ")\n",
    "summary = summarize_paper(\n",
    "    paper=paper,\n",
    "    triage=triage,\n",
    "    raw_fulltext=raw_text,\n",
    "    fulltext_slices=slices,\n",
    "    used_fulltext=True,\n",
    "    notes=json.dumps(meta, sort_keys=True),\n",
    "    llm=summary_client,\n",
    "    prompt_template=SUMMARIZE_PROMPT,\n",
    "    repair_template=REPAIR_PROMPT,\n",
    "    schema=SUMMARY_SCHEMA,\n",
    "    max_input_tokens=120000,\n",
    ")\n",
    "summary\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
